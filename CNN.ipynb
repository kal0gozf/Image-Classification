{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Surprise/1bd930d6a1c717c11be33db74823f661cb53f...</td>\n",
       "      <td>Surprise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Surprise/cropped_emotions.100096~12fffff.png</td>\n",
       "      <td>Surprise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Surprise/0df0e470e33093f5b72a8197fa209d684032c...</td>\n",
       "      <td>Surprise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Surprise/cropped_emotions.260779~12fffff.png</td>\n",
       "      <td>Surprise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Surprise/cropped_emotions.263616~12fffff.png</td>\n",
       "      <td>Surprise</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                path     label\n",
       "0  Surprise/1bd930d6a1c717c11be33db74823f661cb53f...  Surprise\n",
       "1       Surprise/cropped_emotions.100096~12fffff.png  Surprise\n",
       "2  Surprise/0df0e470e33093f5b72a8197fa209d684032c...  Surprise\n",
       "3       Surprise/cropped_emotions.260779~12fffff.png  Surprise\n",
       "4       Surprise/cropped_emotions.263616~12fffff.png  Surprise"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv(\"data.csv\",index_col=0)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Neutral     4027\n",
       "Sad         3934\n",
       "Happy       3740\n",
       "Angry       1313\n",
       "Surprise    1234\n",
       "Ahegao      1205\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.query(\"`label` in ['Angry','Surprise','Ahegao']\")\n",
    "df=df.reset_index(drop=True)\n",
    "df['path']=\"dataset/\"+df['path']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\va472\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import transformers\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision import transforms\n",
    "\n",
    "train_transforms = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Resize((256,256))\n",
    "])\n",
    "\n",
    "# Create Dataset using ImageFolder\n",
    "dataset_train = ImageFolder(\n",
    "    'Data',\n",
    "    transform=train_transforms,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset ImageFolder\n",
       "    Number of datapoints: 3752\n",
       "    Root location: Data\n",
       "    StandardTransform\n",
       "Transform: Compose(\n",
       "               ToTensor()\n",
       "               Resize(size=(256, 256), interpolation=bilinear, max_size=None, antialias=True)\n",
       "           )"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100, 3, 256, 256])\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "dataloader_train = DataLoader(dataset_train,shuffle=True,batch_size=100,)\n",
    "image, label = next(iter(dataloader_train))\n",
    "print(image.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a Deep learning Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model created with 3 classes: ['Ahegao', 'Angry', 'Surprise']\n",
      "Starting training...\n",
      "Epoch [1/5], Step [1/38], Loss: 1.1014, Accuracy: 27.00%\n",
      "Epoch [1/5], Step [11/38], Loss: 1.0370, Accuracy: 38.82%\n",
      "Epoch [1/5], Step [21/38], Loss: 0.9521, Accuracy: 43.52%\n",
      "Epoch [1/5], Step [31/38], Loss: 0.9490, Accuracy: 46.52%\n",
      "Epoch [1/5] completed. Average Loss: 1.1364, Accuracy: 48.88%\n",
      "Epoch [2/5], Step [1/38], Loss: 0.7479, Accuracy: 66.00%\n",
      "Epoch [2/5], Step [11/38], Loss: 0.7434, Accuracy: 62.73%\n",
      "Epoch [2/5], Step [21/38], Loss: 0.7618, Accuracy: 64.67%\n",
      "Epoch [2/5], Step [31/38], Loss: 0.7452, Accuracy: 64.32%\n",
      "Epoch [2/5] completed. Average Loss: 0.7790, Accuracy: 65.43%\n",
      "Epoch [3/5], Step [1/38], Loss: 0.6957, Accuracy: 77.00%\n",
      "Epoch [3/5], Step [11/38], Loss: 0.7118, Accuracy: 70.36%\n",
      "Epoch [3/5], Step [21/38], Loss: 0.5838, Accuracy: 70.71%\n",
      "Epoch [3/5], Step [31/38], Loss: 0.6508, Accuracy: 71.74%\n",
      "Epoch [3/5] completed. Average Loss: 0.6707, Accuracy: 71.62%\n",
      "Epoch [4/5], Step [1/38], Loss: 0.4674, Accuracy: 80.00%\n",
      "Epoch [4/5], Step [11/38], Loss: 0.5167, Accuracy: 75.82%\n",
      "Epoch [4/5], Step [21/38], Loss: 0.5813, Accuracy: 75.43%\n",
      "Epoch [4/5], Step [31/38], Loss: 0.5477, Accuracy: 76.10%\n",
      "Epoch [4/5] completed. Average Loss: 0.5765, Accuracy: 75.83%\n",
      "Epoch [5/5], Step [1/38], Loss: 0.5467, Accuracy: 76.00%\n",
      "Epoch [5/5], Step [11/38], Loss: 0.5620, Accuracy: 78.64%\n",
      "Epoch [5/5], Step [21/38], Loss: 0.4119, Accuracy: 79.62%\n",
      "Epoch [5/5], Step [31/38], Loss: 0.6138, Accuracy: 79.32%\n",
      "Epoch [5/5] completed. Average Loss: 0.5025, Accuracy: 79.58%\n",
      "\n",
      "Evaluating model...\n",
      "Test Accuracy: 81.13%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "81.13006396588486"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# Define the CNN architecture\n",
    "class EmotionCNN(nn.Module):\n",
    "    def __init__(self, num_classes=3):\n",
    "        super(EmotionCNN, self).__init__()\n",
    "        \n",
    "        # Convolutional layers\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
    "        \n",
    "        # Pooling layer\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        \n",
    "        # Dropout for regularization\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        \n",
    "        # Fully connected layers\n",
    "        self.fc1 = nn.Linear(128 * 32 * 32, 512)  # Calculate based on input size\n",
    "        self.fc2 = nn.Linear(512, num_classes)\n",
    "        \n",
    "        # Activation functions\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Standard forward for classification\n",
    "        x = self.pool(self.relu(self.conv1(x)))  # 256x256 -> 128x128\n",
    "        x = self.pool(self.relu(self.conv2(x)))  # 128x128 -> 64x64\n",
    "        x = self.pool(self.relu(self.conv3(x)))  # 64x64 -> 32x32\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.dropout(self.relu(self.fc1(x)))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "    def extract_features(self, x):\n",
    "        # This function returns features before the final classification layer\n",
    "        x = self.pool(self.relu(self.conv1(x)))  # 256x256 -> 128x128\n",
    "        x = self.pool(self.relu(self.conv2(x)))  # 128x128 -> 64x64\n",
    "        x = self.pool(self.relu(self.conv3(x)))  # 64x64 -> 32x32\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc1(x)\n",
    "        return x\n",
    "\n",
    "# Initialize the model\n",
    "model = EmotionCNN(num_classes=len(dataset_train.classes))\n",
    "print(f\"Model created with {len(dataset_train.classes)} classes: {dataset_train.classes}\")\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training function\n",
    "def train_model(model, dataloader, criterion, optimizer, num_epochs=10):\n",
    "    model.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        \n",
    "        for i, (images, labels) in enumerate(dataloader):\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            # Backward pass and optimize\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            # Statistics\n",
    "            running_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            \n",
    "            if i % 10 == 0:\n",
    "                print(f'Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{len(dataloader)}], '\n",
    "                      f'Loss: {loss.item():.4f}, Accuracy: {100 * correct/total:.2f}%')\n",
    "        \n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}] completed. '\n",
    "              f'Average Loss: {running_loss/len(dataloader):.4f}, '\n",
    "              f'Accuracy: {100 * correct/total:.2f}%')\n",
    "\n",
    "# Train the model\n",
    "print(\"Starting training...\")\n",
    "train_model(model, dataloader_train, criterion, optimizer, num_epochs=5)\n",
    "\n",
    "# Evaluation function\n",
    "def evaluate_model(model, dataloader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, labels in dataloader:\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    \n",
    "    accuracy = 100 * correct / total\n",
    "    print(f'Test Accuracy: {accuracy:.2f}%')\n",
    "    return accuracy\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"\\nEvaluating model...\")\n",
    "evaluate_model(model, dataloader_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature extraction (FC layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to generate features for a given dataloader\n",
    "def generate_features(model, dataloader, device='cpu'):\n",
    "    \"\"\"\n",
    "    Extract features from the CNN for all images in the dataloader.\n",
    "    Returns:\n",
    "        features: torch.Tensor of shape (N_samples, feature_dim)\n",
    "        labels: torch.Tensor of shape (N_samples,)\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    features_list = []\n",
    "    labels_list = []\n",
    "    with torch.no_grad():\n",
    "        for images, labels in dataloader:\n",
    "            images = images.to(device)\n",
    "            feats = model.extract_features(images)\n",
    "            features_list.append(feats.cpu())\n",
    "            labels_list.append(labels.cpu())\n",
    "    features = torch.cat(features_list, dim=0)\n",
    "    labels = torch.cat(labels_list, dim=0)\n",
    "    return features, labels\n",
    "\n",
    "features, labels = generate_features(model, dataloader_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_np=features.numpy()\n",
    "labels_np = labels.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "Transformed_df = pd.DataFrame(\n",
    "    np.column_stack([features_np, labels_np])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names=dataloader_train.dataset.classes\n",
    "Transformed_df.iloc[:,-1]=Transformed_df.iloc[:,-1].apply(lambda x: class_names[int(x)])\n",
    "Transformed_df = Transformed_df.rename(columns={Transformed_df.columns[-1]: \"label\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "Transformed_df.to_csv(\"Transformed_features.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\va472\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\va472\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\va472\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\va472\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\va472\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation accuracy scores: [0.85059172 0.83703704 0.82962963 0.84148148 0.85481481]\n",
      "Mean CV accuracy: 0.8427109357878588\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\va472\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set accuracy: 0.8351063829787234\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "      Ahegao       0.87      0.83      0.85       121\n",
      "       Angry       0.86      0.86      0.86       131\n",
      "    Surprise       0.78      0.81      0.80       124\n",
      "\n",
      "    accuracy                           0.84       376\n",
      "   macro avg       0.84      0.83      0.84       376\n",
      "weighted avg       0.84      0.84      0.84       376\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Prepare features and labels\n",
    "X = Transformed_df.iloc[:, :-1].values\n",
    "y = Transformed_df['label'].values\n",
    "\n",
    "# Split into train and test sets (90% train, 10% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.1, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# Initialize logistic regression classifier\n",
    "clf = LogisticRegression(max_iter=1000, solver='lbfgs', multi_class='auto')\n",
    "\n",
    "# Perform cross-validation on training set\n",
    "cv_scores = cross_val_score(clf, X_train, y_train, cv=5, scoring='accuracy')\n",
    "print(\"Cross-validation accuracy scores:\", cv_scores)\n",
    "print(\"Mean CV accuracy:\", cv_scores.mean())\n",
    "\n",
    "# Fit on the full training set\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate on test set\n",
    "y_pred = clf.predict(X_test)\n",
    "test_acc = accuracy_score(y_test, y_pred)\n",
    "print(\"Test set accuracy:\", test_acc)\n",
    "print(\"Classification report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best performance with lower computational cost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation accuracy scores: [0.74852071 0.75703704 0.75555556 0.75703704 0.76296296]\n",
      "Mean CV accuracy: 0.7562226605303528\n",
      "Test set accuracy: 0.7712765957446809\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "      Ahegao       0.77      0.77      0.77       121\n",
      "       Angry       0.83      0.87      0.85       131\n",
      "    Surprise       0.71      0.67      0.69       124\n",
      "\n",
      "    accuracy                           0.77       376\n",
      "   macro avg       0.77      0.77      0.77       376\n",
      "weighted avg       0.77      0.77      0.77       376\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Initialize logistic regression classifier\n",
    "clf = DecisionTreeClassifier()\n",
    "\n",
    "# Perform cross-validation on training set\n",
    "cv_scores = cross_val_score(clf, X_train, y_train, cv=5, scoring='accuracy')\n",
    "print(\"Cross-validation accuracy scores:\", cv_scores)\n",
    "print(\"Mean CV accuracy:\", cv_scores.mean())\n",
    "\n",
    "# Fit on the full training set\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate on test set\n",
    "y_pred = clf.predict(X_test)\n",
    "test_acc = accuracy_score(y_test, y_pred)\n",
    "print(\"Test set accuracy:\", test_acc)\n",
    "print(\"Classification report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation accuracy scores: [0.84023669 0.84444444 0.84148148 0.85037037 0.84444444]\n",
      "Mean CV accuracy: 0.8441954854262546\n",
      "Test set accuracy: 0.848404255319149\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "      Ahegao       0.84      0.85      0.85       121\n",
      "       Angry       0.88      0.94      0.91       131\n",
      "    Surprise       0.81      0.75      0.78       124\n",
      "\n",
      "    accuracy                           0.85       376\n",
      "   macro avg       0.85      0.85      0.85       376\n",
      "weighted avg       0.85      0.85      0.85       376\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "clf = RandomForestClassifier(random_state=42)\n",
    "# Perform cross-validation on training set\n",
    "cv_scores = cross_val_score(clf, X_train, y_train, cv=5, scoring='accuracy')\n",
    "print(\"Cross-validation accuracy scores:\", cv_scores)\n",
    "print(\"Mean CV accuracy:\", cv_scores.mean())\n",
    "\n",
    "# Fit on the full training set\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate on test set\n",
    "y_pred = clf.predict(X_test)\n",
    "test_acc = accuracy_score(y_test, y_pred)\n",
    "print(\"Test set accuracy:\", test_acc)\n",
    "print(\"Classification report:\\n\", classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ada Boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\va472\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\va472\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\va472\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\va472\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\va472\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation accuracy scores: [0.81656805 0.81481481 0.81333333 0.81037037 0.81925926]\n",
      "Mean CV accuracy: 0.8148691650230111\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\va472\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set accuracy: 0.8138297872340425\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "      Ahegao       0.80      0.81      0.81       121\n",
      "       Angry       0.86      0.92      0.89       131\n",
      "    Surprise       0.77      0.71      0.74       124\n",
      "\n",
      "    accuracy                           0.81       376\n",
      "   macro avg       0.81      0.81      0.81       376\n",
      "weighted avg       0.81      0.81      0.81       376\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "clf = AdaBoostClassifier(random_state=42)\n",
    "# Perform cross-validation on training set\n",
    "cv_scores = cross_val_score(clf, X_train, y_train, cv=5, scoring='accuracy')\n",
    "print(\"Cross-validation accuracy scores:\", cv_scores)\n",
    "print(\"Mean CV accuracy:\", cv_scores.mean())\n",
    "\n",
    "# Fit on the full training set\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate on test set\n",
    "y_pred = clf.predict(X_test)\n",
    "test_acc = accuracy_score(y_test, y_pred)\n",
    "print(\"Test set accuracy:\", test_acc)\n",
    "print(\"Classification report:\\n\", classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation accuracy scores: [0.82840237 0.82518519 0.83555556 0.80888889 0.8237037 ]\n",
      "Mean CV accuracy: 0.8243471400394476\n",
      "Test set accuracy: 0.8058510638297872\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "      Ahegao       0.82      0.82      0.82       121\n",
      "       Angry       0.85      0.84      0.84       131\n",
      "    Surprise       0.75      0.76      0.75       124\n",
      "\n",
      "    accuracy                           0.81       376\n",
      "   macro avg       0.81      0.81      0.81       376\n",
      "weighted avg       0.81      0.81      0.81       376\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "\n",
    "# Initialize logistic regression classifier\n",
    "clf = LinearDiscriminantAnalysis()\n",
    "\n",
    "# Perform cross-validation on training set\n",
    "cv_scores = cross_val_score(clf, X_train, y_train, cv=5, scoring='accuracy')\n",
    "print(\"Cross-validation accuracy scores:\", cv_scores)\n",
    "print(\"Mean CV accuracy:\", cv_scores.mean())\n",
    "\n",
    "# Fit on the full training set\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate on test set\n",
    "y_pred = clf.predict(X_test)\n",
    "test_acc = accuracy_score(y_test, y_pred)\n",
    "print(\"Test set accuracy:\", test_acc)\n",
    "print(\"Classification report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### QDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\va472\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\va472\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\va472\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\va472\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\va472\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation accuracy scores: [0.85059172 0.83703704 0.82962963 0.84148148 0.85481481]\n",
      "Mean CV accuracy: 0.8427109357878588\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\va472\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set accuracy: 0.8351063829787234\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "      Ahegao       0.87      0.83      0.85       121\n",
      "       Angry       0.86      0.86      0.86       131\n",
      "    Surprise       0.78      0.81      0.80       124\n",
      "\n",
      "    accuracy                           0.84       376\n",
      "   macro avg       0.84      0.83      0.84       376\n",
      "weighted avg       0.84      0.84      0.84       376\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Prepare features and labels\n",
    "X = Transformed_df.iloc[:, :-1].values\n",
    "y = Transformed_df['label'].values\n",
    "\n",
    "# Split into train and test sets (90% train, 10% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.1, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# Initialize logistic regression classifier\n",
    "clf = LogisticRegression(max_iter=1000, solver='lbfgs', multi_class='auto')\n",
    "\n",
    "# Perform cross-validation on training set\n",
    "cv_scores = cross_val_score(clf, X_train, y_train, cv=5, scoring='accuracy')\n",
    "print(\"Cross-validation accuracy scores:\", cv_scores)\n",
    "print(\"Mean CV accuracy:\", cv_scores.mean())\n",
    "\n",
    "# Fit on the full training set\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate on test set\n",
    "y_pred = clf.predict(X_test)\n",
    "test_acc = accuracy_score(y_test, y_pred)\n",
    "print(\"Test set accuracy:\", test_acc)\n",
    "print(\"Classification report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explained variance ratio: [0.47163078 0.17387935 0.09623474 0.07378868 0.04244696 0.0275414\n",
      " 0.01293464 0.01259039 0.00883025 0.00778296 0.00665696 0.00535737\n",
      " 0.00506648 0.00442342 0.00358005 0.00329685 0.00278813 0.00265827\n",
      " 0.00250393 0.00178139 0.00165739 0.00159226 0.00144962 0.00137686\n",
      " 0.00125597 0.00114795 0.0010648  0.0010196  0.00094123 0.00084383\n",
      " 0.00077624 0.00074288]\n",
      "Total explained variance: 0.9796416146748682\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Standardize the dataset (fit only on train, transform both train and test)\n",
    "scaler = StandardScaler()\n",
    "X_train_std = scaler.fit_transform(X_train)\n",
    "X_test_std = scaler.transform(X_test)\n",
    "\n",
    "# Apply PCA (e.g., keep 10 principal components)\n",
    "pca = PCA(n_components=32)\n",
    "X_train_pca = pca.fit_transform(X_train_std)\n",
    "X_test_pca = pca.transform(X_test_std)\n",
    "\n",
    "print(\"Explained variance ratio:\", pca.explained_variance_ratio_)\n",
    "print(\"Total explained variance:\", pca.explained_variance_ratio_.sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\va472\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\va472\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\va472\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\va472\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation accuracy scores: [0.82248521 0.82518519 0.81037037 0.82518519 0.82962963]\n",
      "Mean CV accuracy: 0.8225711154941925\n",
      "Test set accuracy: 0.8164893617021277\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "      Ahegao       0.84      0.79      0.82       121\n",
      "       Angry       0.86      0.89      0.88       131\n",
      "    Surprise       0.75      0.76      0.75       124\n",
      "\n",
      "    accuracy                           0.82       376\n",
      "   macro avg       0.82      0.81      0.82       376\n",
      "weighted avg       0.82      0.82      0.82       376\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\va472\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\va472\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Initialize logistic regression classifier\n",
    "clf = LogisticRegression(max_iter=1000, solver='lbfgs', multi_class='auto')\n",
    "\n",
    "# Perform cross-validation on training set\n",
    "cv_scores = cross_val_score(clf, X_train_pca, y_train, cv=5, scoring='accuracy')\n",
    "print(\"Cross-validation accuracy scores:\", cv_scores)\n",
    "print(\"Mean CV accuracy:\", cv_scores.mean())\n",
    "\n",
    "# Fit on the full training set\n",
    "clf.fit(X_train_pca, y_train)\n",
    "\n",
    "# Evaluate on test set\n",
    "y_pred = clf.predict(X_test_pca)\n",
    "test_acc = accuracy_score(y_test, y_pred)\n",
    "print(\"Test set accuracy:\", test_acc)\n",
    "print(\"Classification report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Increase test set performance but decrease in cross-validation performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Backward Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected feature indices: [0, 1, 2, 3, 4, 5, 7, 9, 10, 11, 13, 14, 19, 27, 28, 31]\n",
      "Number of selected features: 16\n",
      "Test set accuracy with selected features: 0.8138297872340425\n",
      "Classification report with selected features:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "      Ahegao       0.83      0.77      0.80       121\n",
      "       Angry       0.87      0.89      0.88       131\n",
      "    Surprise       0.74      0.77      0.76       124\n",
      "\n",
      "    accuracy                           0.81       376\n",
      "   macro avg       0.81      0.81      0.81       376\n",
      "weighted avg       0.81      0.81      0.81       376\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\va472\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import SequentialFeatureSelector\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Use the same train/test split as above\n",
    "# X_train, X_test, y_train, y_test already defined\n",
    "\n",
    "# Initialize logistic regression classifier for feature selection\n",
    "selector_clf = LogisticRegression(max_iter=1000, solver='lbfgs', multi_class='auto')\n",
    "\n",
    "# Perform backward selection (elimination) using SequentialFeatureSelector\n",
    "# n_features_to_select can be set as desired, e.g., 20, or 'auto' for automatic selection\n",
    "sfs = SequentialFeatureSelector(\n",
    "    selector_clf,\n",
    "    n_features_to_select='auto',  # or set to a specific number, e.g., 20\n",
    "    direction='backward',\n",
    "    scoring='accuracy',\n",
    "    cv=5,\n",
    "    n_jobs=-1\n",
    ")\n",
    "sfs.fit(X_train_pca, y_train)\n",
    "\n",
    "# Get the mask of selected features\n",
    "selected_features_mask = sfs.get_support()\n",
    "selected_features_indices = [i for i, x in enumerate(selected_features_mask) if x]\n",
    "print(\"Selected feature indices:\", selected_features_indices)\n",
    "print(\"Number of selected features:\", sum(selected_features_mask))\n",
    "\n",
    "# Transform train and test sets to selected features\n",
    "X_train_selected = sfs.transform(X_train_pca)\n",
    "X_test_selected = sfs.transform(X_test_pca)\n",
    "\n",
    "# Retrain classifier on selected features\n",
    "clf_selected = LogisticRegression(max_iter=1000, solver='lbfgs', multi_class='auto')\n",
    "clf_selected.fit(X_train_selected, y_train)\n",
    "\n",
    "# Evaluate on test set\n",
    "y_pred_selected = clf_selected.predict(X_test_selected)\n",
    "test_acc_selected = accuracy_score(y_test, y_pred_selected)\n",
    "print(\"Test set accuracy with selected features:\", test_acc_selected)\n",
    "print(\"Classification report with selected features:\\n\", classification_report(y_test, y_pred_selected))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Increase in accuracy but decrease in F1-score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract the Feature with GAP method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Emotion_extractor(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.feature_extractor = nn.Sequential(\n",
    "            # Layer 1: Conv -> BN -> ELU -> Pool\n",
    "            nn.Conv2d(3, 32, kernel_size=3, padding=1),\n",
    "            nn.ELU(),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "            \n",
    "            # Layer 2: Conv -> BN -> ELU -> Pool\n",
    "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
    "            nn.ELU(),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "            \n",
    "            # Layer 3: Conv -> BN -> ELU -> Pool\n",
    "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
    "            nn.ELU(),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "\n",
    "            nn.AdaptiveAvgPool2d(1),\n",
    "            nn.Flatten()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.feature_extractor(x)       \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = DataLoader(dataset_train,shuffle=False,batch_size=100,)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All features shape: torch.Size([3752, 128])\n",
      "All labels shape: torch.Size([3752])\n"
     ]
    }
   ],
   "source": [
    "# Initialize model\n",
    "ext_model = Emotion_extractor()\n",
    "ext_model.eval()\n",
    "\n",
    "all_features = []\n",
    "all_labels = []\n",
    "\n",
    "# Extract features for a batch\n",
    "for images, labels in dataloader:\n",
    "    with torch.no_grad():\n",
    "        features = ext_model(images)  # Forward pass\n",
    "        all_features.append(features)  # Store batch features\n",
    "        all_labels.append(labels)      # Store corresponding labels\n",
    "# Concatenate all batches into single tensors\n",
    "all_features = torch.cat(all_features, dim=0)  # Shape: [N_samples, feature_dim]\n",
    "all_labels = torch.cat(all_labels, dim=0)      # Shape: [N_samples]\n",
    "\n",
    "# Verify shapes\n",
    "print(f\"All features shape: {all_features.shape}\")  # [Num_samples, Feature_dim]\n",
    "print(f\"All labels shape: {all_labels.shape}\")      # [Num_samples]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_np=all_features.numpy()\n",
    "all_labels_np = all_labels.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "Transformed_df = pd.DataFrame(\n",
    "    np.column_stack([features_np, all_labels_np])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>119</th>\n",
       "      <th>120</th>\n",
       "      <th>121</th>\n",
       "      <th>122</th>\n",
       "      <th>123</th>\n",
       "      <th>124</th>\n",
       "      <th>125</th>\n",
       "      <th>126</th>\n",
       "      <th>127</th>\n",
       "      <th>128</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.117085</td>\n",
       "      <td>0.009221</td>\n",
       "      <td>-0.079122</td>\n",
       "      <td>-0.119097</td>\n",
       "      <td>-0.025123</td>\n",
       "      <td>-0.186836</td>\n",
       "      <td>-0.100694</td>\n",
       "      <td>-0.136923</td>\n",
       "      <td>0.263568</td>\n",
       "      <td>-0.057435</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.104499</td>\n",
       "      <td>-0.076613</td>\n",
       "      <td>0.060868</td>\n",
       "      <td>-0.023425</td>\n",
       "      <td>0.210154</td>\n",
       "      <td>-0.094395</td>\n",
       "      <td>-0.049257</td>\n",
       "      <td>-0.108229</td>\n",
       "      <td>-0.013878</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.112850</td>\n",
       "      <td>0.007841</td>\n",
       "      <td>-0.078589</td>\n",
       "      <td>-0.109645</td>\n",
       "      <td>-0.025417</td>\n",
       "      <td>-0.176733</td>\n",
       "      <td>-0.099483</td>\n",
       "      <td>-0.127217</td>\n",
       "      <td>0.250456</td>\n",
       "      <td>-0.049777</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.097252</td>\n",
       "      <td>-0.073444</td>\n",
       "      <td>0.057944</td>\n",
       "      <td>-0.024694</td>\n",
       "      <td>0.206665</td>\n",
       "      <td>-0.089991</td>\n",
       "      <td>-0.037248</td>\n",
       "      <td>-0.100587</td>\n",
       "      <td>-0.014760</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.103204</td>\n",
       "      <td>0.001466</td>\n",
       "      <td>-0.073323</td>\n",
       "      <td>-0.091821</td>\n",
       "      <td>-0.040404</td>\n",
       "      <td>-0.144515</td>\n",
       "      <td>-0.104588</td>\n",
       "      <td>-0.113104</td>\n",
       "      <td>0.208657</td>\n",
       "      <td>-0.030124</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.080252</td>\n",
       "      <td>-0.067065</td>\n",
       "      <td>0.032545</td>\n",
       "      <td>-0.030524</td>\n",
       "      <td>0.177653</td>\n",
       "      <td>-0.070659</td>\n",
       "      <td>-0.011211</td>\n",
       "      <td>-0.066614</td>\n",
       "      <td>-0.004603</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.119433</td>\n",
       "      <td>0.011938</td>\n",
       "      <td>-0.060380</td>\n",
       "      <td>-0.097906</td>\n",
       "      <td>-0.043307</td>\n",
       "      <td>-0.157708</td>\n",
       "      <td>-0.100221</td>\n",
       "      <td>-0.112822</td>\n",
       "      <td>0.240332</td>\n",
       "      <td>-0.042732</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.090594</td>\n",
       "      <td>-0.067008</td>\n",
       "      <td>0.045575</td>\n",
       "      <td>-0.023394</td>\n",
       "      <td>0.196152</td>\n",
       "      <td>-0.069427</td>\n",
       "      <td>-0.036742</td>\n",
       "      <td>-0.073096</td>\n",
       "      <td>0.000747</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.116311</td>\n",
       "      <td>0.009666</td>\n",
       "      <td>-0.056809</td>\n",
       "      <td>-0.088272</td>\n",
       "      <td>-0.050252</td>\n",
       "      <td>-0.139493</td>\n",
       "      <td>-0.097323</td>\n",
       "      <td>-0.105374</td>\n",
       "      <td>0.227273</td>\n",
       "      <td>-0.039146</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.081966</td>\n",
       "      <td>-0.059505</td>\n",
       "      <td>0.030693</td>\n",
       "      <td>-0.025518</td>\n",
       "      <td>0.179096</td>\n",
       "      <td>-0.061821</td>\n",
       "      <td>-0.027747</td>\n",
       "      <td>-0.056479</td>\n",
       "      <td>0.008409</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  129 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0         1         2         3         4         5         6    \\\n",
       "0  0.117085  0.009221 -0.079122 -0.119097 -0.025123 -0.186836 -0.100694   \n",
       "1  0.112850  0.007841 -0.078589 -0.109645 -0.025417 -0.176733 -0.099483   \n",
       "2  0.103204  0.001466 -0.073323 -0.091821 -0.040404 -0.144515 -0.104588   \n",
       "3  0.119433  0.011938 -0.060380 -0.097906 -0.043307 -0.157708 -0.100221   \n",
       "4  0.116311  0.009666 -0.056809 -0.088272 -0.050252 -0.139493 -0.097323   \n",
       "\n",
       "        7         8         9    ...       119       120       121       122  \\\n",
       "0 -0.136923  0.263568 -0.057435  ... -0.104499 -0.076613  0.060868 -0.023425   \n",
       "1 -0.127217  0.250456 -0.049777  ... -0.097252 -0.073444  0.057944 -0.024694   \n",
       "2 -0.113104  0.208657 -0.030124  ... -0.080252 -0.067065  0.032545 -0.030524   \n",
       "3 -0.112822  0.240332 -0.042732  ... -0.090594 -0.067008  0.045575 -0.023394   \n",
       "4 -0.105374  0.227273 -0.039146  ... -0.081966 -0.059505  0.030693 -0.025518   \n",
       "\n",
       "        123       124       125       126       127  128  \n",
       "0  0.210154 -0.094395 -0.049257 -0.108229 -0.013878  0.0  \n",
       "1  0.206665 -0.089991 -0.037248 -0.100587 -0.014760  0.0  \n",
       "2  0.177653 -0.070659 -0.011211 -0.066614 -0.004603  0.0  \n",
       "3  0.196152 -0.069427 -0.036742 -0.073096  0.000747  0.0  \n",
       "4  0.179096 -0.061821 -0.027747 -0.056479  0.008409  0.0  \n",
       "\n",
       "[5 rows x 129 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Transformed_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names=dataloader.dataset.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "Transformed_df.iloc[:,-1]=Transformed_df.iloc[:,-1].apply(lambda x: class_names[int(x)])\n",
    "Transformed_df = Transformed_df.rename(columns={Transformed_df.columns[-1]: \"label\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "Transformed_df.to_csv(\"Transformed_features2.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\va472\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\va472\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\va472\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\va472\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\va472\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation accuracy scores: [0.49260355 0.52740741 0.51851852 0.52740741 0.50518519]\n",
      "Mean CV accuracy: 0.5142244137628753\n",
      "Test set accuracy: 0.5212765957446809\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "      Ahegao       0.58      0.68      0.63       121\n",
      "       Angry       0.49      0.63      0.55       131\n",
      "    Surprise       0.48      0.26      0.34       124\n",
      "\n",
      "    accuracy                           0.52       376\n",
      "   macro avg       0.52      0.52      0.50       376\n",
      "weighted avg       0.51      0.52      0.50       376\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\va472\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Prepare features and labels\n",
    "X = Transformed_df.iloc[:, :-1].values\n",
    "y = Transformed_df['label'].values\n",
    "\n",
    "# Split into train and test sets (90% train, 10% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.1, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# Initialize logistic regression classifier\n",
    "clf = LogisticRegression(max_iter=1000, solver='lbfgs', multi_class='auto')\n",
    "\n",
    "# Perform cross-validation on training set\n",
    "cv_scores = cross_val_score(clf, X_train, y_train, cv=5, scoring='accuracy')\n",
    "print(\"Cross-validation accuracy scores:\", cv_scores)\n",
    "print(\"Mean CV accuracy:\", cv_scores.mean())\n",
    "\n",
    "# Fit on the full training set\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate on test set\n",
    "y_pred = clf.predict(X_test)\n",
    "test_acc = accuracy_score(y_test, y_pred)\n",
    "print(\"Test set accuracy:\", test_acc)\n",
    "print(\"Classification report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decision Tree\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation accuracy scores: [0.48668639 0.51111111 0.45481481 0.4962963  0.44888889]\n",
      "Mean CV accuracy: 0.47955950032873107\n",
      "Test set accuracy: 0.45478723404255317\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "      Ahegao       0.53      0.50      0.51       121\n",
      "       Angry       0.47      0.46      0.47       131\n",
      "    Surprise       0.38      0.40      0.39       124\n",
      "\n",
      "    accuracy                           0.45       376\n",
      "   macro avg       0.46      0.46      0.46       376\n",
      "weighted avg       0.46      0.45      0.46       376\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Initialize logistic regression classifier\n",
    "clf = DecisionTreeClassifier()\n",
    "\n",
    "# Perform cross-validation on training set\n",
    "cv_scores = cross_val_score(clf, X_train, y_train, cv=5, scoring='accuracy')\n",
    "print(\"Cross-validation accuracy scores:\", cv_scores)\n",
    "print(\"Mean CV accuracy:\", cv_scores.mean())\n",
    "\n",
    "# Fit on the full training set\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate on test set\n",
    "y_pred = clf.predict(X_test)\n",
    "test_acc = accuracy_score(y_test, y_pred)\n",
    "print(\"Test set accuracy:\", test_acc)\n",
    "print(\"Classification report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation accuracy scores: [0.70266272 0.72888889 0.73333333 0.7362963  0.73481481]\n",
      "Mean CV accuracy: 0.7271992110453649\n",
      "Test set accuracy: 0.7180851063829787\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "      Ahegao       0.82      0.79      0.80       121\n",
      "       Angry       0.70      0.78      0.74       131\n",
      "    Surprise       0.63      0.59      0.61       124\n",
      "\n",
      "    accuracy                           0.72       376\n",
      "   macro avg       0.72      0.72      0.72       376\n",
      "weighted avg       0.72      0.72      0.72       376\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "\n",
    "# Initialize logistic regression classifier\n",
    "clf = LinearDiscriminantAnalysis()\n",
    "\n",
    "# Perform cross-validation on training set\n",
    "cv_scores = cross_val_score(clf, X_train, y_train, cv=5, scoring='accuracy')\n",
    "print(\"Cross-validation accuracy scores:\", cv_scores)\n",
    "print(\"Mean CV accuracy:\", cv_scores.mean())\n",
    "\n",
    "# Fit on the full training set\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate on test set\n",
    "y_pred = clf.predict(X_test)\n",
    "test_acc = accuracy_score(y_test, y_pred)\n",
    "print(\"Test set accuracy:\", test_acc)\n",
    "print(\"Classification report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "QDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation accuracy scores: [0.64201183 0.66814815 0.62962963 0.63703704 0.67703704]\n",
      "Mean CV accuracy: 0.6507727372342756\n",
      "Test set accuracy: 0.625\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "      Ahegao       0.73      0.67      0.70       121\n",
      "       Angry       0.71      0.57      0.63       131\n",
      "    Surprise       0.50      0.64      0.56       124\n",
      "\n",
      "    accuracy                           0.62       376\n",
      "   macro avg       0.64      0.63      0.63       376\n",
      "weighted avg       0.65      0.62      0.63       376\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "\n",
    "clf = QuadraticDiscriminantAnalysis()\n",
    "# Perform cross-validation on training set\n",
    "cv_scores = cross_val_score(clf, X_train, y_train, cv=5, scoring='accuracy')\n",
    "print(\"Cross-validation accuracy scores:\", cv_scores)\n",
    "print(\"Mean CV accuracy:\", cv_scores.mean())\n",
    "\n",
    "# Fit on the full training set\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate on test set\n",
    "y_pred = clf.predict(X_test)\n",
    "test_acc = accuracy_score(y_test, y_pred)\n",
    "print(\"Test set accuracy:\", test_acc)\n",
    "print(\"Classification report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation accuracy scores: [0.52218935 0.56       0.57481481 0.55555556 0.55703704]\n",
      "Mean CV accuracy: 0.5539193513039666\n",
      "Test set accuracy: 0.5585106382978723\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "      Ahegao       0.61      0.65      0.63       121\n",
      "       Angry       0.54      0.63      0.58       131\n",
      "    Surprise       0.52      0.39      0.44       124\n",
      "\n",
      "    accuracy                           0.56       376\n",
      "   macro avg       0.56      0.56      0.55       376\n",
      "weighted avg       0.56      0.56      0.55       376\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "clf = RandomForestClassifier(random_state=42)\n",
    "# Perform cross-validation on training set\n",
    "cv_scores = cross_val_score(clf, X_train, y_train, cv=5, scoring='accuracy')\n",
    "print(\"Cross-validation accuracy scores:\", cv_scores)\n",
    "print(\"Mean CV accuracy:\", cv_scores.mean())\n",
    "\n",
    "# Fit on the full training set\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate on test set\n",
    "y_pred = clf.predict(X_test)\n",
    "test_acc = accuracy_score(y_test, y_pred)\n",
    "print(\"Test set accuracy:\", test_acc)\n",
    "print(\"Classification report:\\n\", classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ada boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\va472\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\va472\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\va472\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\va472\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\va472\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation accuracy scores: [0.52810651 0.53925926 0.55407407 0.54814815 0.52592593]\n",
      "Mean CV accuracy: 0.5391027832566294\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\va472\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set accuracy: 0.5425531914893617\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "      Ahegao       0.56      0.66      0.61       121\n",
      "       Angry       0.55      0.59      0.57       131\n",
      "    Surprise       0.51      0.38      0.43       124\n",
      "\n",
      "    accuracy                           0.54       376\n",
      "   macro avg       0.54      0.54      0.54       376\n",
      "weighted avg       0.54      0.54      0.54       376\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "clf = AdaBoostClassifier(random_state=42)\n",
    "# Perform cross-validation on training set\n",
    "cv_scores = cross_val_score(clf, X_train, y_train, cv=5, scoring='accuracy')\n",
    "print(\"Cross-validation accuracy scores:\", cv_scores)\n",
    "print(\"Mean CV accuracy:\", cv_scores.mean())\n",
    "\n",
    "# Fit on the full training set\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate on test set\n",
    "y_pred = clf.predict(X_test)\n",
    "test_acc = accuracy_score(y_test, y_pred)\n",
    "print(\"Test set accuracy:\", test_acc)\n",
    "print(\"Classification report:\\n\", classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gradient boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation accuracy scores: [0.53550296 0.60296296 0.58666667 0.5762963  0.5762963 ]\n",
      "Mean CV accuracy: 0.5755450361604207\n",
      "Test set accuracy: 0.5531914893617021\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "      Ahegao       0.59      0.65      0.62       121\n",
      "       Angry       0.55      0.60      0.57       131\n",
      "    Surprise       0.50      0.41      0.45       124\n",
      "\n",
      "    accuracy                           0.55       376\n",
      "   macro avg       0.55      0.55      0.55       376\n",
      "weighted avg       0.55      0.55      0.55       376\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "clf = GradientBoostingClassifier(random_state=42)\n",
    "# Perform cross-validation on training set\n",
    "cv_scores = cross_val_score(clf, X_train, y_train, cv=5, scoring='accuracy')\n",
    "print(\"Cross-validation accuracy scores:\", cv_scores)\n",
    "print(\"Mean CV accuracy:\", cv_scores.mean())\n",
    "\n",
    "# Fit on the full training set\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate on test set\n",
    "y_pred = clf.predict(X_test)\n",
    "test_acc = accuracy_score(y_test, y_pred)\n",
    "print(\"Test set accuracy:\", test_acc)\n",
    "print(\"Classification report:\\n\", classification_report(y_test, y_pred))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
